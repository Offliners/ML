{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPeZlgEieAfGX5jedkw5dug",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Offliners/NTUML2021_Hung-yi-Lee/blob/main/HW2/homework2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghYxMSxsmAYm"
      },
      "source": [
        "# **Homework 2-1 Phoneme Classification**\r\n",
        "\r\n",
        "The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus (TIMIT)\r\n",
        "The TIMIT corpus of reading speech has been designed to provide speech data for the acquisition of acoustic-phonetic knowledge and for the development and evaluation of automatic speech recognition systems.\r\n",
        "\r\n",
        "This homework is a multiclass classification task, we are going to train a deep neural network classifier to predict the phonemes for each frame from the speech corpus TIMIT.\r\n",
        "\r\n",
        "## **Download Data**\r\n",
        "link: https://academictorrents.com/details/34e2b78745138186976cbc27939b1b34d18bd5b3\r\n",
        "\r\n",
        "timit_11/\r\n",
        "\r\n",
        "* train_11.npy: training data\r\n",
        "* train_label_11.npy: training label\r\n",
        "* test_11.npy: testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N98vZGvSl-Fq",
        "outputId": "fe22416d-c33c-422d-9a71-ea4d0646b403"
      },
      "source": [
        "!gdown --id '1duKUYSwilRG6BF8cLz8L_LRGDE7EFLHG' --output data.zip\r\n",
        "!unzip data.zip\r\n",
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1duKUYSwilRG6BF8cLz8L_LRGDE7EFLHG\n",
            "To: /content/data.zip\n",
            "376MB [00:02, 178MB/s]\n",
            "Archive:  data.zip\n",
            "replace sampleSubmission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: sampleSubmission.csv    \n",
            "  inflating: timit_11/timit_11/test_11.npy  \n",
            "  inflating: timit_11/timit_11/train_11.npy  \n",
            "  inflating: timit_11/timit_11/train_label_11.npy  \n",
            "data.zip    prediction.csv  sampleSubmission.csv\n",
            "model.ckpt  sample_data     timit_11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ffxBMT3mU5g"
      },
      "source": [
        "# **Preparing Data**\r\n",
        "\r\n",
        "Load the training and testing data from the .npy file (NumPy array)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRTYp6bemeRk",
        "outputId": "0ffb1ab1-abca-4b36-dda0-1b44c94e682f"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "print('Loading data ...')\r\n",
        "\r\n",
        "data_root='./timit_11/timit_11/'\r\n",
        "train = np.load(data_root + 'train_11.npy')\r\n",
        "train_label = np.load(data_root + 'train_label_11.npy')\r\n",
        "test = np.load(data_root + 'test_11.npy')\r\n",
        "\r\n",
        "print('Size of training data: {}'.format(train.shape))\r\n",
        "print('Size of testing data: {}'.format(test.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data ...\n",
            "Size of training data: (1229932, 429)\n",
            "Size of testing data: (451552, 429)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpQ84yh8me6A"
      },
      "source": [
        "# **Create Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPvM4GoFmhzo"
      },
      "source": [
        "import torch\r\n",
        "from torch.utils.data import Dataset\r\n",
        "\r\n",
        "class TIMITDataset(Dataset):\r\n",
        "    def __init__(self, X, y=None):\r\n",
        "        self.data = torch.from_numpy(X).float()\r\n",
        "        if y is not None:\r\n",
        "            y = y.astype(np.int)\r\n",
        "            self.label = torch.LongTensor(y)\r\n",
        "        else:\r\n",
        "            self.label = None\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        if self.label is not None:\r\n",
        "            return self.data[idx], self.label[idx]\r\n",
        "        else:\r\n",
        "            return self.data[idx]\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmKia2rfmmk9",
        "outputId": "5156822c-a4ee-41ec-8869-f85d10654e2b"
      },
      "source": [
        "VAL_RATIO = 0.2\r\n",
        "\r\n",
        "percent = int(train.shape[0] * (1 - VAL_RATIO))\r\n",
        "train_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]\r\n",
        "print('Size of training set: {}'.format(train_x.shape))\r\n",
        "print('Size of validation set: {}'.format(val_x.shape))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training set: (983945, 429)\n",
            "Size of validation set: (245987, 429)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA1fNcNamqKa"
      },
      "source": [
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "train_set = TIMITDataset(train_x, train_y)\r\n",
        "val_set = TIMITDataset(val_x, val_y)\r\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\r\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kqycVinmj11"
      },
      "source": [
        "#### **notes: if you need to use these variables later, then you may remove this block or clean up unneeded variables later the data size is quite huge, so be aware of memory usage in colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7dGNUuGmtDD",
        "outputId": "de103d5e-89d2-4ac8-d387-06ede44b7fae"
      },
      "source": [
        "import gc\r\n",
        "\r\n",
        "del train, train_label, train_x, train_y, val_x, val_y\r\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "626"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXFtiY94m6X-"
      },
      "source": [
        "# **Create Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfFT6XJ8nBCS"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "\r\n",
        "class Classifier(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Classifier, self).__init__()\r\n",
        "        self.layer1 = nn.Linear(429, 1024)\r\n",
        "        self.layer2 = nn.Linear(1024, 1024)\r\n",
        "        self.layer3 = nn.Linear(1024, 512)\r\n",
        "        self.layer4 = nn.Linear(512, 128)\r\n",
        "        self.out = nn.Linear(128, 39) \r\n",
        "        self.dp = nn.Dropout(0.2)\r\n",
        "        self.bn1 = nn.BatchNorm1d(1024)\r\n",
        "        self.bn2 = nn.BatchNorm1d(1024)\r\n",
        "        self.bn3 = nn.BatchNorm1d(512)\r\n",
        "        self.bn4 = nn.BatchNorm1d(128)\r\n",
        "\r\n",
        "        self.act_fn = nn.ReLU()\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.layer1(x)\r\n",
        "        x = self.act_fn(x)\r\n",
        "        x = self.bn1(x)\r\n",
        "        x = self.dp(x)\r\n",
        "\r\n",
        "        x = self.layer2(x)\r\n",
        "        x = self.act_fn(x)\r\n",
        "        x = self.bn2(x)\r\n",
        "        x = self.dp(x)\r\n",
        "\r\n",
        "        x = self.layer3(x)\r\n",
        "        x = self.act_fn(x)\r\n",
        "        x = self.bn3(x)\r\n",
        "        x = self.dp(x)\r\n",
        "\r\n",
        "        x = self.layer4(x)\r\n",
        "        x = self.act_fn(x)\r\n",
        "        x = self.bn4(x)\r\n",
        "        x = self.dp(x)\r\n",
        "\r\n",
        "        x = self.out(x)\r\n",
        "        \r\n",
        "        return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GLq4t_knLUL"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBsChEconOOV",
        "outputId": "690ca05c-b945-4d44-8830-50f3d4de3ead"
      },
      "source": [
        "#check device\r\n",
        "def get_device():\r\n",
        "  return 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "\r\n",
        "# fix random seed\r\n",
        "def same_seeds(seed):\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        torch.cuda.manual_seed(seed)\r\n",
        "        torch.cuda.manual_seed_all(seed)  \r\n",
        "    np.random.seed(seed)  \r\n",
        "    torch.backends.cudnn.benchmark = False\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "\r\n",
        "# fix random seed for reproducibility\r\n",
        "same_seeds(0)\r\n",
        "\r\n",
        "# get device \r\n",
        "device = get_device()\r\n",
        "print(f'DEVICE: {device}')\r\n",
        "\r\n",
        "# training parameters\r\n",
        "num_epoch = 50               # number of training epoch\r\n",
        "learning_rate = 1e-4         # learning rate\r\n",
        "l2 = 1e-3                    # L2 regularization\r\n",
        "\r\n",
        "# the path where checkpoint saved\r\n",
        "model_path = './model.ckpt'\r\n",
        "\r\n",
        "# create model, define a loss function, and optimizer\r\n",
        "model = Classifier().to(device)\r\n",
        "criterion = nn.CrossEntropyLoss() \r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyjl3itJnWwL",
        "outputId": "7d329a0b-b9e4-47a3-9e37-f0771aecf55b"
      },
      "source": [
        "# start training\r\n",
        "\r\n",
        "best_acc = 0.0\r\n",
        "for epoch in range(num_epoch):\r\n",
        "    train_acc = 0.0\r\n",
        "    train_loss = 0.0\r\n",
        "    val_acc = 0.0\r\n",
        "    val_loss = 0.0\r\n",
        "\r\n",
        "    # training\r\n",
        "    model.train() # set the model to training mode\r\n",
        "    for i, data in enumerate(train_loader):\r\n",
        "        inputs, labels = data\r\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "        optimizer.zero_grad() \r\n",
        "        outputs = model(inputs) \r\n",
        "        batch_loss = criterion(outputs, labels)\r\n",
        "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\r\n",
        "        batch_loss.backward() \r\n",
        "        optimizer.step() \r\n",
        "\r\n",
        "        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\r\n",
        "        train_loss += batch_loss.item()\r\n",
        "\r\n",
        "    # validation\r\n",
        "    if len(val_set) > 0:\r\n",
        "        model.eval() # set the model to evaluation mode\r\n",
        "        with torch.no_grad():\r\n",
        "            for i, data in enumerate(val_loader):\r\n",
        "                inputs, labels = data\r\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "                outputs = model(inputs)\r\n",
        "                batch_loss = criterion(outputs, labels) \r\n",
        "                _, val_pred = torch.max(outputs, 1) \r\n",
        "            \r\n",
        "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\r\n",
        "                val_loss += batch_loss.item()\r\n",
        "\r\n",
        "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\r\n",
        "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\r\n",
        "            ))\r\n",
        "\r\n",
        "            # if the model improves, save a checkpoint at this epoch\r\n",
        "            if val_acc > best_acc:\r\n",
        "                best_acc = val_acc\r\n",
        "                torch.save(model.state_dict(), model_path)\r\n",
        "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\r\n",
        "    else:\r\n",
        "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\r\n",
        "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\r\n",
        "        ))\r\n",
        "\r\n",
        "# if not validating, save the last epoch\r\n",
        "if len(val_set) == 0:\r\n",
        "    torch.save(model.state_dict(), model_path)\r\n",
        "    print('saving model at last epoch')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[001/050] Train Acc: 0.596807 Loss: 1.345627 | Val Acc: 0.680906 loss: 1.007506\n",
            "saving model with acc 0.681\n",
            "[002/050] Train Acc: 0.656547 Loss: 1.098082 | Val Acc: 0.703322 loss: 0.927632\n",
            "saving model with acc 0.703\n",
            "[003/050] Train Acc: 0.674257 Loss: 1.032516 | Val Acc: 0.711534 loss: 0.895454\n",
            "saving model with acc 0.712\n",
            "[004/050] Train Acc: 0.684883 Loss: 0.995615 | Val Acc: 0.717961 loss: 0.872389\n",
            "saving model with acc 0.718\n",
            "[005/050] Train Acc: 0.690611 Loss: 0.972359 | Val Acc: 0.720233 loss: 0.863176\n",
            "saving model with acc 0.720\n",
            "[006/050] Train Acc: 0.695414 Loss: 0.955617 | Val Acc: 0.723782 loss: 0.852447\n",
            "saving model with acc 0.724\n",
            "[007/050] Train Acc: 0.698942 Loss: 0.944950 | Val Acc: 0.725010 loss: 0.847013\n",
            "saving model with acc 0.725\n",
            "[008/050] Train Acc: 0.701675 Loss: 0.934210 | Val Acc: 0.727242 loss: 0.834629\n",
            "saving model with acc 0.727\n",
            "[009/050] Train Acc: 0.702943 Loss: 0.928351 | Val Acc: 0.726888 loss: 0.837118\n",
            "[010/050] Train Acc: 0.704603 Loss: 0.923349 | Val Acc: 0.730173 loss: 0.826333\n",
            "saving model with acc 0.730\n",
            "[011/050] Train Acc: 0.706118 Loss: 0.917873 | Val Acc: 0.728388 loss: 0.833326\n",
            "[012/050] Train Acc: 0.707150 Loss: 0.912686 | Val Acc: 0.729957 loss: 0.827580\n",
            "[013/050] Train Acc: 0.708108 Loss: 0.909554 | Val Acc: 0.731953 loss: 0.818536\n",
            "saving model with acc 0.732\n",
            "[014/050] Train Acc: 0.708882 Loss: 0.905899 | Val Acc: 0.733730 loss: 0.819369\n",
            "saving model with acc 0.734\n",
            "[015/050] Train Acc: 0.710623 Loss: 0.902500 | Val Acc: 0.732579 loss: 0.821200\n",
            "[016/050] Train Acc: 0.710816 Loss: 0.900667 | Val Acc: 0.734892 loss: 0.810567\n",
            "saving model with acc 0.735\n",
            "[017/050] Train Acc: 0.711313 Loss: 0.899638 | Val Acc: 0.732388 loss: 0.815575\n",
            "[018/050] Train Acc: 0.711848 Loss: 0.896890 | Val Acc: 0.733018 loss: 0.813545\n",
            "[019/050] Train Acc: 0.711561 Loss: 0.896098 | Val Acc: 0.733275 loss: 0.816212\n",
            "[020/050] Train Acc: 0.712274 Loss: 0.894025 | Val Acc: 0.735372 loss: 0.811890\n",
            "saving model with acc 0.735\n",
            "[021/050] Train Acc: 0.712822 Loss: 0.893344 | Val Acc: 0.736397 loss: 0.805995\n",
            "saving model with acc 0.736\n",
            "[022/050] Train Acc: 0.713206 Loss: 0.891310 | Val Acc: 0.736937 loss: 0.808993\n",
            "saving model with acc 0.737\n",
            "[023/050] Train Acc: 0.713019 Loss: 0.891108 | Val Acc: 0.734084 loss: 0.809538\n",
            "[024/050] Train Acc: 0.714457 Loss: 0.889083 | Val Acc: 0.736319 loss: 0.803321\n",
            "[025/050] Train Acc: 0.713726 Loss: 0.888878 | Val Acc: 0.735742 loss: 0.807113\n",
            "[026/050] Train Acc: 0.714293 Loss: 0.887075 | Val Acc: 0.737880 loss: 0.802533\n",
            "saving model with acc 0.738\n",
            "[027/050] Train Acc: 0.714494 Loss: 0.887348 | Val Acc: 0.736730 loss: 0.805922\n",
            "[028/050] Train Acc: 0.715156 Loss: 0.884580 | Val Acc: 0.738011 loss: 0.799535\n",
            "saving model with acc 0.738\n",
            "[029/050] Train Acc: 0.715532 Loss: 0.884490 | Val Acc: 0.737836 loss: 0.800595\n",
            "[030/050] Train Acc: 0.715320 Loss: 0.884314 | Val Acc: 0.737372 loss: 0.802862\n",
            "[031/050] Train Acc: 0.715430 Loss: 0.883418 | Val Acc: 0.738015 loss: 0.800171\n",
            "saving model with acc 0.738\n",
            "[032/050] Train Acc: 0.715120 Loss: 0.883963 | Val Acc: 0.736905 loss: 0.803848\n",
            "[033/050] Train Acc: 0.715474 Loss: 0.882839 | Val Acc: 0.737722 loss: 0.802597\n",
            "[034/050] Train Acc: 0.716255 Loss: 0.881386 | Val Acc: 0.737303 loss: 0.804366\n",
            "[035/050] Train Acc: 0.716486 Loss: 0.881291 | Val Acc: 0.737112 loss: 0.805553\n",
            "[036/050] Train Acc: 0.716222 Loss: 0.881882 | Val Acc: 0.737763 loss: 0.800889\n",
            "[037/050] Train Acc: 0.716218 Loss: 0.882170 | Val Acc: 0.737185 loss: 0.804136\n",
            "[038/050] Train Acc: 0.716668 Loss: 0.880081 | Val Acc: 0.734628 loss: 0.808591\n",
            "[039/050] Train Acc: 0.716799 Loss: 0.879535 | Val Acc: 0.738356 loss: 0.801346\n",
            "saving model with acc 0.738\n",
            "[040/050] Train Acc: 0.717124 Loss: 0.878966 | Val Acc: 0.739092 loss: 0.799350\n",
            "saving model with acc 0.739\n",
            "[041/050] Train Acc: 0.717161 Loss: 0.878900 | Val Acc: 0.738181 loss: 0.798387\n",
            "[042/050] Train Acc: 0.716811 Loss: 0.879086 | Val Acc: 0.738661 loss: 0.796650\n",
            "[043/050] Train Acc: 0.717177 Loss: 0.878244 | Val Acc: 0.738193 loss: 0.802410\n",
            "[044/050] Train Acc: 0.717311 Loss: 0.876910 | Val Acc: 0.737246 loss: 0.801000\n",
            "[045/050] Train Acc: 0.717391 Loss: 0.877236 | Val Acc: 0.738104 loss: 0.803518\n",
            "[046/050] Train Acc: 0.717506 Loss: 0.876422 | Val Acc: 0.738759 loss: 0.799182\n",
            "[047/050] Train Acc: 0.717507 Loss: 0.875773 | Val Acc: 0.738641 loss: 0.799412\n",
            "[048/050] Train Acc: 0.717677 Loss: 0.876196 | Val Acc: 0.738783 loss: 0.797935\n",
            "[049/050] Train Acc: 0.718304 Loss: 0.875228 | Val Acc: 0.739250 loss: 0.796638\n",
            "saving model with acc 0.739\n",
            "[050/050] Train Acc: 0.718306 Loss: 0.873979 | Val Acc: 0.737324 loss: 0.801161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uTr80Panaq8"
      },
      "source": [
        "# **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiBILuUEncLl",
        "outputId": "a2ae4cd4-a2fd-4e51-f987-08f3ece89bb9"
      },
      "source": [
        "# create testing dataset\r\n",
        "test_set = TIMITDataset(test, None)\r\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\r\n",
        "\r\n",
        "# create model and load weights from checkpoint\r\n",
        "model = Classifier().to(device)\r\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP_tUJeLnd94"
      },
      "source": [
        "predict = []\r\n",
        "model.eval() # set the model to evaluation mode\r\n",
        "with torch.no_grad():\r\n",
        "    for i, data in enumerate(test_loader):\r\n",
        "        inputs = data\r\n",
        "        inputs = inputs.to(device)\r\n",
        "        outputs = model(inputs)\r\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\r\n",
        "\r\n",
        "        for y in test_pred.cpu().numpy():\r\n",
        "            predict.append(y)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fIjAsNTnhgs"
      },
      "source": [
        "# **Write prediction to a CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "athJ5R7BnlN5",
        "outputId": "65b3b1d5-ad13-45bf-ca13-7999364fe627"
      },
      "source": [
        "with open('prediction.csv', 'w') as f:\r\n",
        "    f.write('Id,Class\\n')\r\n",
        "    for i, y in enumerate(predict):\r\n",
        "        f.write('{},{}\\n'.format(i, y))\r\n",
        "\r\n",
        "print('Saving results to prediction.csv')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving results to prediction.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV5cHjHLos62"
      },
      "source": [
        "# **Reference**\r\n",
        "\r\n",
        "Source: Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW02/HW02-1.ipynb)"
      ]
    }
  ]
}